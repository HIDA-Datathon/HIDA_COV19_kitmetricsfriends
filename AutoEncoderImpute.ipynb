{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/trainSet.txt')\n",
    "test = pd.read_csv('data/testSet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_vars = ['RespiratoryFailure', 'Sex', 'Cough', 'DifficultyInBreathing', 'CardiovascularDisease']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder should work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    regularizer = keras.regularizers.l1_l2(l1=0.0, l2=0.0)\n",
    "    \n",
    "    inputs = keras.Input(shape=(16,))\n",
    "    \n",
    "    x = keras.layers.Dense(16, activation='relu')(inputs)\n",
    "    # build a little auto-encoder\n",
    "    x = keras.layers.Dense(160, activation='relu', kernel_regularizer=regularizer)(x)\n",
    "    x = keras.layers.Dropout(0.25)(x)\n",
    "    # bottleneck\n",
    "    x = keras.layers.Dense(8, activation='relu', kernel_regularizer=regularizer)(x)\n",
    "    x = keras.layers.Dropout(0.25)(x)\n",
    "    x = keras.layers.Dense(160, activation='relu', kernel_regularizer=regularizer)(x)\n",
    "    x = keras.layers.Dropout(0.25)(x)\n",
    "    \n",
    "    out1 = keras.layers.Dense(16, activation='sigmoid')(x)\n",
    "    out2 = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, {'impute': out1, 'classify':out2})\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/keras-team/keras/issues/7065\n",
    "def masked_mse(mask_value=-1):\n",
    "    def f(y_true, y_pred):\n",
    "        mask_true = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "        masked_squared_error = K.square(mask_true * (y_true - y_pred))\n",
    "        masked_mse = K.sum(masked_squared_error, axis=-1) / K.sum(mask_true, axis=-1)\n",
    "        return masked_mse * 100\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer_validation(valid_set):\n",
    "    \"\"\"\n",
    "    Function to remove extra fields from data for validation.\n",
    "    \"\"\"\n",
    "    fields_removed = valid_set.copy()\n",
    "    imputer_mask = np.zeros(valid_set.shape)\n",
    "    for n, row in enumerate(fields_removed):\n",
    "        non_nan = np.where(row != -1)[0]\n",
    "        set_nan = np.random.choice(non_nan)\n",
    "        fields_removed[n, set_nan] = -1\n",
    "        imputer_mask[n, set_nan] = True\n",
    "    \n",
    "    return fields_removed, imputer_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(x_true, x_pred, errorfun='mse', scaler=None):\n",
    "    if scaler:\n",
    "        x_true = scaler.inverse_transform(x_true.copy())\n",
    "        x_pred = scaler.inverse_transform(x_pred.copy())\n",
    "        x_true = np.clip(x_true, a_min=-1, a_max=None)\n",
    "        x_pred = np.clip(x_pred, a_min=-1, a_max=None)\n",
    "    if errorfun == 'mse':\n",
    "        score = mean_squared_error(x_true, x_pred)\n",
    "    elif errorfun == 'acc':\n",
    "        score = accuracy_score(x_true, x_pred > 0.5)\n",
    "    elif errorfun == \"masked_mse\":\n",
    "        score = masked_mse(-1)(x_true, x_pred)\n",
    "        score = np.mean(score)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to remove:\n",
    "cols_out = ['PatientID', 'ImageFile', 'Hospital', 'Prognosis']\n",
    "impute_cols = [i for i in train.columns if i not in cols_out]\n",
    "# split validation and prediction\n",
    "train_clean = train[impute_cols]\n",
    "train_y = train['Prognosis'] == 'MILD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorize hospitals, and use hospitals for cross-validation\n",
    "train.Hospital, mapping_index = train.Hospital.factorize()\n",
    "PF = PredefinedSplit(train['Hospital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split D, with validation n = 139: \n",
      "Rescaled MSE - 125896808.00 MSE - 1.97 Acc - 0.65\n",
      "Impute MSE - 8.96 Impute MSE scaled - 30325944.00\n",
      "Train - MSE 0.550, ACC 0.633\n",
      "==============================================\n",
      "Split E, with validation n = 101: \n",
      "Rescaled MSE - 200913.61 MSE - 0.49 Acc - 0.64\n",
      "Impute MSE - 10.23 Impute MSE scaled - 52554.90\n",
      "Train - MSE 0.519, ACC 0.668\n",
      "==============================================\n",
      "Split F, with validation n = 488: \n",
      "Rescaled MSE - 91947280.00 MSE - 2.01 Acc - 0.62\n",
      "Impute MSE - 15.98 Impute MSE scaled - 236450928.00\n",
      "Train - MSE 0.480, ACC 0.691\n",
      "==============================================\n",
      "Split B, with validation n = 104: \n",
      "Rescaled MSE - 127791816.00 MSE - 0.94 Acc - 0.66\n",
      "Impute MSE - 14.18 Impute MSE scaled - 1187535.88\n",
      "Train - MSE 0.549, ACC 0.648\n",
      "==============================================\n",
      "Split C, with validation n = 31: \n",
      "Rescaled MSE - 10188045.00 MSE - 0.66 Acc - 0.55\n",
      "Impute MSE - 19.50 Impute MSE scaled - 94413816.00\n",
      "Train - MSE 0.508, ACC 0.656\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "accs, mses0, mses1, imps0, imps1, trues, preds = [], [], [], [], [], [], []\n",
    "\n",
    "train_mask = np.isnan(train_clean).values\n",
    "\n",
    "for n, (tr, vl) in enumerate(PF.split(train)):\n",
    "    model = create_model()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "                  loss={'impute': masked_mse(), 'classify': 'binary_crossentropy'},\n",
    "                  metrics={'impute': 'mse', 'classify': 'accuracy'})\n",
    "    MM = MinMaxScaler(clip=True)\n",
    "    \n",
    "    # Remove Nans\n",
    "    x_train = train_clean.iloc[tr].copy().fillna(0)\n",
    "    x_valid = train_clean.iloc[vl].copy().fillna(0)\n",
    "    # Define y-values\n",
    "    y_train = train_y.iloc[tr]\n",
    "    y_valid = train_y.iloc[vl]\n",
    "    # Scale data from 0 to 1\n",
    "    x_train = MM.fit_transform(x_train)\n",
    "    x_valid = MM.transform(x_valid)\n",
    "    \n",
    "    # Set former nan values to -1\n",
    "    x_train[train_mask[tr]] = -1\n",
    "    x_valid[train_mask[vl]] = -1\n",
    "    \n",
    "    # Fit Model\n",
    "    model.fit(x_train, {'impute':x_train, 'classify': y_train}, verbose=0, callbacks=[early_stopping], validation_split=0.15,\n",
    "             epochs=250)\n",
    "    \n",
    "    # Predict the things\n",
    "    prediction = model.predict(x_valid)\n",
    "    preds.append(MM.inverse_transform(prediction['impute']))\n",
    "\n",
    "    pred_val, pred_y = prediction['impute'], prediction['classify']\n",
    "    \n",
    "    \n",
    "    # Returns metrics, weirdly\n",
    "    _, _, _, train_acc, train_mse = model.evaluate(x_train, \n",
    "                                                   {'impute':x_train, \n",
    "                                                    'classify': y_train}, \n",
    "                                                   verbose=0)\n",
    "    \n",
    "    # Set previous NAN to -1\n",
    "    pred_val[train_mask[vl]] = -1\n",
    "    x_valid[train_mask[vl]] = -1\n",
    "    \n",
    "    # imputer validation:\n",
    "    x_impute, impute_mask = imputer_validation(x_valid)\n",
    "    \n",
    "    imputer_predict = model.predict(x_impute)['impute']\n",
    "    imputer_predict[impute_mask==False] = -1\n",
    "    \n",
    "    validation_mask = x_valid.copy()\n",
    "    validation_mask[impute_mask==False] = -1\n",
    "    \n",
    "    # imputer error\n",
    "    imp0 = calculate_score(validation_mask, \n",
    "                            imputer_predict, errorfun='masked_mse')\n",
    "    imp1 = calculate_score(validation_mask, \n",
    "                            imputer_predict, errorfun='masked_mse', scaler=MM)\n",
    "    \n",
    "    # Keepingt track\n",
    "    imps0.append(imp0)\n",
    "    imps1.append(imp1)\n",
    "    mses0.append(calculate_score(x_valid, pred_val, scaler=MM, errorfun='masked_mse'))\n",
    "    mses1.append(calculate_score(x_valid, pred_val, errorfun='masked_mse'))\n",
    "    accs.append(calculate_score(y_valid, pred_y, errorfun='acc'))\n",
    "    trues.append(MM.inverse_transform(x_valid))\n",
    "    preds.append(MM.inverse_transform(prediction['impute']))\n",
    "    print(f\"Split {mapping_index[n]}, with validation n = {x_valid.shape[0]}: \\nRescaled MSE - {mses0[-1]:4.2f} \" +\n",
    "          f\"MSE - {mses1[-1]:4.2f} \" +\n",
    "          f\"Acc - {accs[-1]:4.2f}\\n\" +\n",
    "          f\"Impute MSE - {imps0[-1]:4.2f} \" +\n",
    "          f\"Impute MSE scaled - {imps1[-1]:4.2f}\")\n",
    "          \n",
    "    print(f\"Train - MSE {train_mse:4.3f}, ACC {train_acc:4.3f}\")\n",
    "    \n",
    "    print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_df = pd.DataFrame(np.clip(np.vstack(trues), a_min=0, a_max=None), columns = train_clean.columns)\n",
    "rescaled_preds = pd.DataFrame(np.clip(np.vstack(preds), a_min=0, a_max=None), columns = train_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Training and Creating Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 16.6600 - dense_53_loss: 0.6972 - dense_52_loss: 15.9628 - dense_53_accuracy: 0.5157 - dense_52_mape: 91486464.0000 - val_loss: 13.6221 - val_dense_53_loss: 0.7141 - val_dense_52_loss: 12.9079 - val_dense_53_accuracy: 0.4385 - val_dense_52_mape: 90756280.0000\n",
      "Epoch 2/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 10.9408 - dense_53_loss: 0.7035 - dense_52_loss: 10.2373 - dense_53_accuracy: 0.5211 - dense_52_mape: 66191052.0000 - val_loss: 9.4696 - val_dense_53_loss: 0.6895 - val_dense_52_loss: 8.7802 - val_dense_53_accuracy: 0.5385 - val_dense_52_mape: 63303568.0000\n",
      "Epoch 3/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 9.3490 - dense_53_loss: 0.7147 - dense_52_loss: 8.6343 - dense_53_accuracy: 0.4925 - dense_52_mape: 58938004.0000 - val_loss: 9.0078 - val_dense_53_loss: 0.7043 - val_dense_52_loss: 8.3035 - val_dense_53_accuracy: 0.4385 - val_dense_52_mape: 65503904.0000\n",
      "Epoch 4/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 8.8289 - dense_53_loss: 0.7083 - dense_52_loss: 8.1205 - dense_53_accuracy: 0.5266 - dense_52_mape: 57572564.0000 - val_loss: 8.5399 - val_dense_53_loss: 0.6946 - val_dense_52_loss: 7.8453 - val_dense_53_accuracy: 0.5308 - val_dense_52_mape: 61753636.0000\n",
      "Epoch 5/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 8.4934 - dense_53_loss: 0.7021 - dense_52_loss: 7.7913 - dense_53_accuracy: 0.5007 - dense_52_mape: 56707280.0000 - val_loss: 7.9959 - val_dense_53_loss: 0.6931 - val_dense_52_loss: 7.3028 - val_dense_53_accuracy: 0.5769 - val_dense_52_mape: 59507212.0000\n",
      "Epoch 6/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 7.6714 - dense_53_loss: 0.6918 - dense_52_loss: 6.9796 - dense_53_accuracy: 0.5471 - dense_52_mape: 51100696.0000 - val_loss: 6.8079 - val_dense_53_loss: 0.6831 - val_dense_52_loss: 6.1247 - val_dense_53_accuracy: 0.5692 - val_dense_52_mape: 50623676.0000\n",
      "Epoch 7/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 7.0983 - dense_53_loss: 0.6982 - dense_52_loss: 6.4001 - dense_53_accuracy: 0.5334 - dense_52_mape: 46471064.0000 - val_loss: 6.0042 - val_dense_53_loss: 0.6828 - val_dense_52_loss: 5.3215 - val_dense_53_accuracy: 0.5692 - val_dense_52_mape: 43838932.0000\n",
      "Epoch 8/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6.3625 - dense_53_loss: 0.6829 - dense_52_loss: 5.6797 - dense_53_accuracy: 0.5621 - dense_52_mape: 41491864.0000 - val_loss: 5.4716 - val_dense_53_loss: 0.6748 - val_dense_52_loss: 4.7968 - val_dense_53_accuracy: 0.5692 - val_dense_52_mape: 40531624.0000\n",
      "Epoch 9/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6.1022 - dense_53_loss: 0.6754 - dense_52_loss: 5.4268 - dense_53_accuracy: 0.5553 - dense_52_mape: 39863928.0000 - val_loss: 5.0470 - val_dense_53_loss: 0.6616 - val_dense_52_loss: 4.3854 - val_dense_53_accuracy: 0.6154 - val_dense_52_mape: 35092868.0000\n",
      "Epoch 10/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5.6927 - dense_53_loss: 0.6701 - dense_52_loss: 5.0226 - dense_53_accuracy: 0.5921 - dense_52_mape: 36644620.0000 - val_loss: 4.6316 - val_dense_53_loss: 0.6661 - val_dense_52_loss: 3.9655 - val_dense_53_accuracy: 0.6154 - val_dense_52_mape: 32733808.0000\n",
      "Epoch 11/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5.2371 - dense_53_loss: 0.6727 - dense_52_loss: 4.5644 - dense_53_accuracy: 0.5894 - dense_52_mape: 33552474.0000 - val_loss: 4.3473 - val_dense_53_loss: 0.6687 - val_dense_52_loss: 3.6786 - val_dense_53_accuracy: 0.6231 - val_dense_52_mape: 29125182.0000\n",
      "Epoch 12/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5.1009 - dense_53_loss: 0.6578 - dense_52_loss: 4.4431 - dense_53_accuracy: 0.6207 - dense_52_mape: 31076624.0000 - val_loss: 3.9605 - val_dense_53_loss: 0.6691 - val_dense_52_loss: 3.2914 - val_dense_53_accuracy: 0.5692 - val_dense_52_mape: 28264200.0000\n",
      "Epoch 13/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4.8409 - dense_53_loss: 0.6468 - dense_52_loss: 4.1940 - dense_53_accuracy: 0.6303 - dense_52_mape: 30459206.0000 - val_loss: 3.6794 - val_dense_53_loss: 0.6670 - val_dense_52_loss: 3.0124 - val_dense_53_accuracy: 0.5846 - val_dense_52_mape: 27046062.0000\n",
      "Epoch 14/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4.4841 - dense_53_loss: 0.6665 - dense_52_loss: 3.8176 - dense_53_accuracy: 0.6057 - dense_52_mape: 27322880.0000 - val_loss: 3.4701 - val_dense_53_loss: 0.6656 - val_dense_52_loss: 2.8046 - val_dense_53_accuracy: 0.6000 - val_dense_52_mape: 24694286.0000\n",
      "Epoch 15/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4.3653 - dense_53_loss: 0.6677 - dense_52_loss: 3.6976 - dense_53_accuracy: 0.6139 - dense_52_mape: 25262824.0000 - val_loss: 3.2647 - val_dense_53_loss: 0.6685 - val_dense_52_loss: 2.5963 - val_dense_53_accuracy: 0.6154 - val_dense_52_mape: 24093638.0000\n",
      "Epoch 16/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4.2046 - dense_53_loss: 0.6681 - dense_52_loss: 3.5365 - dense_53_accuracy: 0.5907 - dense_52_mape: 24835024.0000 - val_loss: 3.1002 - val_dense_53_loss: 0.6630 - val_dense_52_loss: 2.4372 - val_dense_53_accuracy: 0.6154 - val_dense_52_mape: 22917752.0000\n",
      "Epoch 17/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4.1786 - dense_53_loss: 0.6643 - dense_52_loss: 3.5142 - dense_53_accuracy: 0.6071 - dense_52_mape: 23649910.0000 - val_loss: 2.9457 - val_dense_53_loss: 0.6614 - val_dense_52_loss: 2.2842 - val_dense_53_accuracy: 0.6231 - val_dense_52_mape: 21838782.0000\n",
      "Epoch 18/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.9258 - dense_53_loss: 0.6625 - dense_52_loss: 3.2633 - dense_53_accuracy: 0.6030 - dense_52_mape: 23665246.0000 - val_loss: 2.7234 - val_dense_53_loss: 0.6569 - val_dense_52_loss: 2.0666 - val_dense_53_accuracy: 0.6154 - val_dense_52_mape: 18684452.0000\n",
      "Epoch 19/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.5705 - dense_53_loss: 0.6692 - dense_52_loss: 2.9014 - dense_53_accuracy: 0.6139 - dense_52_mape: 20524392.0000 - val_loss: 2.4426 - val_dense_53_loss: 0.6606 - val_dense_52_loss: 1.7820 - val_dense_53_accuracy: 0.6385 - val_dense_52_mape: 16628409.0000\n",
      "Epoch 20/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.6963 - dense_53_loss: 0.6687 - dense_52_loss: 3.0276 - dense_53_accuracy: 0.6207 - dense_52_mape: 21022972.0000 - val_loss: 2.2253 - val_dense_53_loss: 0.6693 - val_dense_52_loss: 1.5559 - val_dense_53_accuracy: 0.6231 - val_dense_52_mape: 11953998.0000\n",
      "Epoch 21/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.4555 - dense_53_loss: 0.6522 - dense_52_loss: 2.8033 - dense_53_accuracy: 0.6303 - dense_52_mape: 18911232.0000 - val_loss: 2.1448 - val_dense_53_loss: 0.6698 - val_dense_52_loss: 1.4750 - val_dense_53_accuracy: 0.6385 - val_dense_52_mape: 11756969.0000\n",
      "Epoch 22/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.3536 - dense_53_loss: 0.6567 - dense_52_loss: 2.6969 - dense_53_accuracy: 0.6126 - dense_52_mape: 17866982.0000 - val_loss: 2.0427 - val_dense_53_loss: 0.6643 - val_dense_52_loss: 1.3784 - val_dense_53_accuracy: 0.6154 - val_dense_52_mape: 10824238.0000\n",
      "Epoch 23/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.5502 - dense_53_loss: 0.6775 - dense_52_loss: 2.8727 - dense_53_accuracy: 0.6303 - dense_52_mape: 18892918.0000 - val_loss: 2.0314 - val_dense_53_loss: 0.6568 - val_dense_52_loss: 1.3746 - val_dense_53_accuracy: 0.6154 - val_dense_52_mape: 11571152.0000\n",
      "Epoch 24/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.1694 - dense_53_loss: 0.6761 - dense_52_loss: 2.4933 - dense_53_accuracy: 0.5935 - dense_52_mape: 17356656.0000 - val_loss: 1.9892 - val_dense_53_loss: 0.6628 - val_dense_52_loss: 1.3265 - val_dense_53_accuracy: 0.6000 - val_dense_52_mape: 11406953.0000\n",
      "Epoch 25/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.1693 - dense_53_loss: 0.6761 - dense_52_loss: 2.4933 - dense_53_accuracy: 0.5839 - dense_52_mape: 16173479.0000 - val_loss: 1.8516 - val_dense_53_loss: 0.6551 - val_dense_52_loss: 1.1965 - val_dense_53_accuracy: 0.6154 - val_dense_52_mape: 7502172.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.1165 - dense_53_loss: 0.6577 - dense_52_loss: 2.4588 - dense_53_accuracy: 0.6098 - dense_52_mape: 16570104.0000 - val_loss: 1.8516 - val_dense_53_loss: 0.6542 - val_dense_52_loss: 1.1975 - val_dense_53_accuracy: 0.6154 - val_dense_52_mape: 8274979.5000\n",
      "Epoch 27/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.8093 - dense_53_loss: 0.6719 - dense_52_loss: 2.1374 - dense_53_accuracy: 0.6248 - dense_52_mape: 13479127.0000 - val_loss: 1.8204 - val_dense_53_loss: 0.6549 - val_dense_52_loss: 1.1655 - val_dense_53_accuracy: 0.6154 - val_dense_52_mape: 6990893.5000\n",
      "Epoch 28/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.0172 - dense_53_loss: 0.6610 - dense_52_loss: 2.3562 - dense_53_accuracy: 0.6221 - dense_52_mape: 15585395.0000 - val_loss: 1.7989 - val_dense_53_loss: 0.6616 - val_dense_52_loss: 1.1373 - val_dense_53_accuracy: 0.6385 - val_dense_52_mape: 6535187.5000\n",
      "Epoch 29/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.7408 - dense_53_loss: 0.6672 - dense_52_loss: 2.0736 - dense_53_accuracy: 0.6044 - dense_52_mape: 14584572.0000 - val_loss: 1.8069 - val_dense_53_loss: 0.6570 - val_dense_52_loss: 1.1499 - val_dense_53_accuracy: 0.6385 - val_dense_52_mape: 6262883.0000\n",
      "Epoch 30/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.9259 - dense_53_loss: 0.6557 - dense_52_loss: 2.2702 - dense_53_accuracy: 0.6398 - dense_52_mape: 13069151.0000 - val_loss: 1.7896 - val_dense_53_loss: 0.6606 - val_dense_52_loss: 1.1290 - val_dense_53_accuracy: 0.6462 - val_dense_52_mape: 6829166.0000\n",
      "Epoch 31/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.6253 - dense_53_loss: 0.6473 - dense_52_loss: 1.9781 - dense_53_accuracy: 0.6385 - dense_52_mape: 13313058.0000 - val_loss: 1.7598 - val_dense_53_loss: 0.6598 - val_dense_52_loss: 1.1000 - val_dense_53_accuracy: 0.6385 - val_dense_52_mape: 5291856.5000\n",
      "Epoch 32/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.9867 - dense_53_loss: 0.6600 - dense_52_loss: 2.3267 - dense_53_accuracy: 0.6207 - dense_52_mape: 14174538.0000 - val_loss: 1.7952 - val_dense_53_loss: 0.6605 - val_dense_52_loss: 1.1347 - val_dense_53_accuracy: 0.6462 - val_dense_52_mape: 6138809.5000\n",
      "Epoch 33/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.6004 - dense_53_loss: 0.6618 - dense_52_loss: 1.9386 - dense_53_accuracy: 0.6194 - dense_52_mape: 11779011.0000 - val_loss: 1.7521 - val_dense_53_loss: 0.6602 - val_dense_52_loss: 1.0920 - val_dense_53_accuracy: 0.6385 - val_dense_52_mape: 5486541.5000\n",
      "Epoch 34/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.7816 - dense_53_loss: 0.6680 - dense_52_loss: 2.1136 - dense_53_accuracy: 0.6126 - dense_52_mape: 13458649.0000 - val_loss: 1.7344 - val_dense_53_loss: 0.6570 - val_dense_52_loss: 1.0774 - val_dense_53_accuracy: 0.6385 - val_dense_52_mape: 4664193.0000\n",
      "Epoch 35/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.7281 - dense_53_loss: 0.6596 - dense_52_loss: 2.0685 - dense_53_accuracy: 0.6207 - dense_52_mape: 12758801.0000 - val_loss: 1.7486 - val_dense_53_loss: 0.6606 - val_dense_52_loss: 1.0880 - val_dense_53_accuracy: 0.6538 - val_dense_52_mape: 4591815.0000\n",
      "Epoch 36/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.7251 - dense_53_loss: 0.6723 - dense_52_loss: 2.0528 - dense_53_accuracy: 0.6044 - dense_52_mape: 12634116.0000 - val_loss: 1.7402 - val_dense_53_loss: 0.6563 - val_dense_52_loss: 1.0839 - val_dense_53_accuracy: 0.6308 - val_dense_52_mape: 4491924.0000\n",
      "Epoch 37/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.4615 - dense_53_loss: 0.6645 - dense_52_loss: 1.7970 - dense_53_accuracy: 0.6085 - dense_52_mape: 10794667.0000 - val_loss: 1.7331 - val_dense_53_loss: 0.6579 - val_dense_52_loss: 1.0752 - val_dense_53_accuracy: 0.6385 - val_dense_52_mape: 4140839.0000\n",
      "Epoch 38/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.6163 - dense_53_loss: 0.6645 - dense_52_loss: 1.9517 - dense_53_accuracy: 0.6071 - dense_52_mape: 11561496.0000 - val_loss: 1.7105 - val_dense_53_loss: 0.6579 - val_dense_52_loss: 1.0526 - val_dense_53_accuracy: 0.6000 - val_dense_52_mape: 3892871.5000\n",
      "Epoch 39/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.5437 - dense_53_loss: 0.6619 - dense_52_loss: 1.8818 - dense_53_accuracy: 0.6248 - dense_52_mape: 11694574.0000 - val_loss: 1.7271 - val_dense_53_loss: 0.6661 - val_dense_52_loss: 1.0611 - val_dense_53_accuracy: 0.6308 - val_dense_52_mape: 3418744.0000\n",
      "Epoch 40/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.5509 - dense_53_loss: 0.6664 - dense_52_loss: 1.8845 - dense_53_accuracy: 0.5989 - dense_52_mape: 10637336.0000 - val_loss: 1.7440 - val_dense_53_loss: 0.6632 - val_dense_52_loss: 1.0808 - val_dense_53_accuracy: 0.6077 - val_dense_52_mape: 3379200.2500\n",
      "Epoch 41/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.3772 - dense_53_loss: 0.6572 - dense_52_loss: 1.7200 - dense_53_accuracy: 0.6098 - dense_52_mape: 9551507.0000 - val_loss: 1.7095 - val_dense_53_loss: 0.6639 - val_dense_52_loss: 1.0456 - val_dense_53_accuracy: 0.6308 - val_dense_52_mape: 3563678.0000\n",
      "Epoch 42/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.5346 - dense_53_loss: 0.6579 - dense_52_loss: 1.8767 - dense_53_accuracy: 0.6221 - dense_52_mape: 10294453.0000 - val_loss: 1.7006 - val_dense_53_loss: 0.6595 - val_dense_52_loss: 1.0411 - val_dense_53_accuracy: 0.6462 - val_dense_52_mape: 3737192.0000\n",
      "Epoch 43/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.4390 - dense_53_loss: 0.6604 - dense_52_loss: 1.7786 - dense_53_accuracy: 0.6426 - dense_52_mape: 10284155.0000 - val_loss: 1.7192 - val_dense_53_loss: 0.6679 - val_dense_52_loss: 1.0513 - val_dense_53_accuracy: 0.6538 - val_dense_52_mape: 3201259.0000\n",
      "Epoch 44/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.4015 - dense_53_loss: 0.6533 - dense_52_loss: 1.7482 - dense_53_accuracy: 0.6330 - dense_52_mape: 9478943.0000 - val_loss: 1.6981 - val_dense_53_loss: 0.6616 - val_dense_52_loss: 1.0365 - val_dense_53_accuracy: 0.6385 - val_dense_52_mape: 3086180.7500\n",
      "Epoch 45/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.4262 - dense_53_loss: 0.6474 - dense_52_loss: 1.7788 - dense_53_accuracy: 0.6344 - dense_52_mape: 9793855.0000 - val_loss: 1.7213 - val_dense_53_loss: 0.6566 - val_dense_52_loss: 1.0647 - val_dense_53_accuracy: 0.6462 - val_dense_52_mape: 3243133.2500\n",
      "Epoch 46/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.5332 - dense_53_loss: 0.6614 - dense_52_loss: 1.8718 - dense_53_accuracy: 0.6207 - dense_52_mape: 10819219.0000 - val_loss: 1.7358 - val_dense_53_loss: 0.6641 - val_dense_52_loss: 1.0716 - val_dense_53_accuracy: 0.6462 - val_dense_52_mape: 2943266.7500\n",
      "Epoch 47/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.3921 - dense_53_loss: 0.6596 - dense_52_loss: 1.7325 - dense_53_accuracy: 0.6289 - dense_52_mape: 9005563.0000 - val_loss: 1.6900 - val_dense_53_loss: 0.6633 - val_dense_52_loss: 1.0267 - val_dense_53_accuracy: 0.6385 - val_dense_52_mape: 2990692.5000\n",
      "Epoch 48/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.3239 - dense_53_loss: 0.6647 - dense_52_loss: 1.6592 - dense_53_accuracy: 0.6235 - dense_52_mape: 9051045.0000 - val_loss: 1.6685 - val_dense_53_loss: 0.6589 - val_dense_52_loss: 1.0096 - val_dense_53_accuracy: 0.6538 - val_dense_52_mape: 3162208.0000\n",
      "Epoch 49/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.5116 - dense_53_loss: 0.6665 - dense_52_loss: 1.8450 - dense_53_accuracy: 0.6044 - dense_52_mape: 10553044.0000 - val_loss: 1.7157 - val_dense_53_loss: 0.6652 - val_dense_52_loss: 1.0506 - val_dense_53_accuracy: 0.6385 - val_dense_52_mape: 3250908.2500\n",
      "Epoch 50/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.4800 - dense_53_loss: 0.6603 - dense_52_loss: 1.8196 - dense_53_accuracy: 0.6112 - dense_52_mape: 9892166.0000 - val_loss: 1.6918 - val_dense_53_loss: 0.6601 - val_dense_52_loss: 1.0317 - val_dense_53_accuracy: 0.6385 - val_dense_52_mape: 2765003.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.3515 - dense_53_loss: 0.6595 - dense_52_loss: 1.6920 - dense_53_accuracy: 0.6139 - dense_52_mape: 9019416.0000 - val_loss: 1.6840 - val_dense_53_loss: 0.6624 - val_dense_52_loss: 1.0216 - val_dense_53_accuracy: 0.6615 - val_dense_52_mape: 2791454.2500\n",
      "Epoch 52/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.3234 - dense_53_loss: 0.6565 - dense_52_loss: 1.6669 - dense_53_accuracy: 0.6235 - dense_52_mape: 9155167.0000 - val_loss: 1.6680 - val_dense_53_loss: 0.6556 - val_dense_52_loss: 1.0124 - val_dense_53_accuracy: 0.6462 - val_dense_52_mape: 2319961.0000\n",
      "Epoch 53/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.3633 - dense_53_loss: 0.6734 - dense_52_loss: 1.6899 - dense_53_accuracy: 0.6057 - dense_52_mape: 9087580.0000 - val_loss: 1.6792 - val_dense_53_loss: 0.6633 - val_dense_52_loss: 1.0159 - val_dense_53_accuracy: 0.6385 - val_dense_52_mape: 2647713.0000\n",
      "Epoch 54/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.2302 - dense_53_loss: 0.6501 - dense_52_loss: 1.5801 - dense_53_accuracy: 0.6357 - dense_52_mape: 8419584.0000 - val_loss: 1.6670 - val_dense_53_loss: 0.6604 - val_dense_52_loss: 1.0066 - val_dense_53_accuracy: 0.6231 - val_dense_52_mape: 2513561.5000\n",
      "Epoch 55/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.4563 - dense_53_loss: 0.6453 - dense_52_loss: 1.8110 - dense_53_accuracy: 0.6289 - dense_52_mape: 10030607.0000 - val_loss: 1.6827 - val_dense_53_loss: 0.6626 - val_dense_52_loss: 1.0201 - val_dense_53_accuracy: 0.6538 - val_dense_52_mape: 2717475.5000\n",
      "Epoch 56/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.4412 - dense_53_loss: 0.6525 - dense_52_loss: 1.7888 - dense_53_accuracy: 0.6262 - dense_52_mape: 10038209.0000 - val_loss: 1.6952 - val_dense_53_loss: 0.6600 - val_dense_52_loss: 1.0352 - val_dense_53_accuracy: 0.6154 - val_dense_52_mape: 2858587.7500\n",
      "Epoch 57/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.3472 - dense_53_loss: 0.6542 - dense_52_loss: 1.6930 - dense_53_accuracy: 0.6344 - dense_52_mape: 9107856.0000 - val_loss: 1.6704 - val_dense_53_loss: 0.6589 - val_dense_52_loss: 1.0114 - val_dense_53_accuracy: 0.6077 - val_dense_52_mape: 2557699.7500\n",
      "Epoch 58/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.4802 - dense_53_loss: 0.6593 - dense_52_loss: 1.8209 - dense_53_accuracy: 0.6085 - dense_52_mape: 10130526.0000 - val_loss: 1.7021 - val_dense_53_loss: 0.6610 - val_dense_52_loss: 1.0411 - val_dense_53_accuracy: 0.6077 - val_dense_52_mape: 2179255.5000\n",
      "Epoch 59/250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.6427 - dense_53_loss: 0.6531 - dense_52_loss: 1.9896 - dense_53_accuracy: 0.6180 - dense_52_mape: 11050815.0000 - val_loss: 1.6910 - val_dense_53_loss: 0.6641 - val_dense_52_loss: 1.0269 - val_dense_53_accuracy: 0.6077 - val_dense_52_mape: 2605148.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bfaa5f5588>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "                  loss={'impute': masked_mse(), 'classify': 'binary_crossentropy'},\n",
    "                  metrics={'impute': 'mape', 'classify': 'accuracy'})\n",
    "\n",
    "MM = MinMaxScaler(clip=True)\n",
    "\n",
    "# Transform Data:\n",
    "x_train = train_clean.copy().fillna(0)\n",
    "# Define y-values\n",
    "y_train = train_y\n",
    "# Scale data from 0 to 1\n",
    "x_train = MM.fit_transform(x_train)\n",
    "# Set former nan values to -1\n",
    "x_train[train_mask] = -1\n",
    "\n",
    "\n",
    "model.fit(x_train, {'impute':x_train, 'classify': y_train}, verbose=1, callbacks=[early_stopping], validation_split=0.15,\n",
    "             epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean = test[impute_cols] \n",
    "x_test = test_clean.copy().fillna(0)\n",
    "x_test = MM.transform(x_test)\n",
    "x_test[np.isnan(test_clean)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predidctions\n",
    "imputations = predictions['impute']\n",
    "classify = predictions['classify']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_values = test_clean.copy().values\n",
    "imputed_thing = np.zeros(previous_values.shape)\n",
    "\n",
    "imputed_thing[np.isnan(test_clean)] = MM.inverse_transform(imputations)[np.isnan(test_clean)]\n",
    "imputed_thing = np.clip(imputed_thing, a_min=0, a_max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_thing[np.isnan(test_clean)==False] = previous_values[np.isnan(test_clean)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = pd.DataFrame(imputed_thing, columns=test_clean.columns)\n",
    "test_out[binary_vars] = (test_out[binary_vars] > 0.5) * 1.0\n",
    "test_out['Prognosis'] = classify > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out.loc[test_out['Prognosis'] == True, 'Prognosis'] = 'MILD'\n",
    "test_out.loc[test_out['Prognosis'] == False, 'Prognosis'] = 'SEVERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out[['PatientID', 'ImageFile', 'Hospital']] = test[['PatientID', 'ImageFile', 'Hospital']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = test_out[test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Temp_C</th>\n",
       "      <th>Cough</th>\n",
       "      <th>DifficultyInBreathing</th>\n",
       "      <th>WBC</th>\n",
       "      <th>CRP</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>LDH</th>\n",
       "      <th>Ddimer</th>\n",
       "      <th>Ox_percentage</th>\n",
       "      <th>PaO2</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>pH</th>\n",
       "      <th>CardiovascularDisease</th>\n",
       "      <th>RespiratoryFailure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.484394</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>37.925557</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>6.956501</td>\n",
       "      <td>12.117571</td>\n",
       "      <td>603.156421</td>\n",
       "      <td>319.731508</td>\n",
       "      <td>1073.452809</td>\n",
       "      <td>93.404331</td>\n",
       "      <td>71.080574</td>\n",
       "      <td>94.285997</td>\n",
       "      <td>7.495585</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.02500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.198359</td>\n",
       "      <td>0.439554</td>\n",
       "      <td>1.213976</td>\n",
       "      <td>0.500979</td>\n",
       "      <td>0.483915</td>\n",
       "      <td>2.483231</td>\n",
       "      <td>13.757640</td>\n",
       "      <td>41.623326</td>\n",
       "      <td>170.133271</td>\n",
       "      <td>1527.853532</td>\n",
       "      <td>4.826866</td>\n",
       "      <td>21.347838</td>\n",
       "      <td>4.354086</td>\n",
       "      <td>0.157690</td>\n",
       "      <td>0.460179</td>\n",
       "      <td>0.15678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>527.183044</td>\n",
       "      <td>28.198984</td>\n",
       "      <td>1.055853</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>30.635891</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>6.913150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.147500</td>\n",
       "      <td>2.649895</td>\n",
       "      <td>573.586044</td>\n",
       "      <td>162.508957</td>\n",
       "      <td>99.221571</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>57.470881</td>\n",
       "      <td>91.790400</td>\n",
       "      <td>7.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>61.034046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.927573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.916075</td>\n",
       "      <td>7.449948</td>\n",
       "      <td>599.353668</td>\n",
       "      <td>319.200470</td>\n",
       "      <td>391.812439</td>\n",
       "      <td>94.565804</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>7.480000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.925000</td>\n",
       "      <td>15.777942</td>\n",
       "      <td>622.236145</td>\n",
       "      <td>425.250000</td>\n",
       "      <td>1171.129272</td>\n",
       "      <td>97.258677</td>\n",
       "      <td>80.390287</td>\n",
       "      <td>97.750393</td>\n",
       "      <td>7.542500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.720000</td>\n",
       "      <td>75.839714</td>\n",
       "      <td>761.324585</td>\n",
       "      <td>1159.000000</td>\n",
       "      <td>7274.918457</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7.915079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age         Sex      Temp_C       Cough  DifficultyInBreathing  \\\n",
       "count  120.000000  120.000000  120.000000  120.000000             120.000000   \n",
       "mean    60.484394    0.258333   37.925557    0.466667               0.366667   \n",
       "std     13.198359    0.439554    1.213976    0.500979               0.483915   \n",
       "min     27.000000    0.000000   36.000000    0.000000               0.000000   \n",
       "25%     51.000000    0.000000   37.000000    0.000000               0.000000   \n",
       "50%     61.034046    0.000000   37.927573    0.000000               0.000000   \n",
       "75%     67.000000    1.000000   39.000000    1.000000               1.000000   \n",
       "max     95.000000    1.000000   41.500000    1.000000               1.000000   \n",
       "\n",
       "              WBC         CRP  Fibrinogen          LDH       Ddimer  \\\n",
       "count  120.000000  120.000000  120.000000   120.000000   120.000000   \n",
       "mean     6.956501   12.117571  603.156421   319.731508  1073.452809   \n",
       "std      2.483231   13.757640   41.623326   170.133271  1527.853532   \n",
       "min      2.300000    0.140000  527.183044    28.198984     1.055853   \n",
       "25%      5.147500    2.649895  573.586044   162.508957    99.221571   \n",
       "50%      6.916075    7.449948  599.353668   319.200470   391.812439   \n",
       "75%      7.925000   15.777942  622.236145   425.250000  1171.129272   \n",
       "max     17.720000   75.839714  761.324585  1159.000000  7274.918457   \n",
       "\n",
       "       Ox_percentage        PaO2        SaO2          pH  \\\n",
       "count     120.000000  120.000000  120.000000  120.000000   \n",
       "mean       93.404331   71.080574   94.285997    7.495585   \n",
       "std         4.826866   21.347838    4.354086    0.157690   \n",
       "min        70.000000   30.635891   77.000000    6.913150   \n",
       "25%        90.000000   57.470881   91.790400    7.440000   \n",
       "50%        94.565804   69.000000   96.000000    7.480000   \n",
       "75%        97.258677   80.390287   97.750393    7.542500   \n",
       "max       100.000000  175.000000  100.000000    7.915079   \n",
       "\n",
       "       CardiovascularDisease  RespiratoryFailure  \n",
       "count             120.000000           120.00000  \n",
       "mean                0.300000             0.02500  \n",
       "std                 0.460179             0.15678  \n",
       "min                 0.000000             0.00000  \n",
       "25%                 0.000000             0.00000  \n",
       "50%                 0.000000             0.00000  \n",
       "75%                 1.000000             0.00000  \n",
       "max                 1.000000             1.00000  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Handson",
   "language": "python",
   "name": "handson_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
