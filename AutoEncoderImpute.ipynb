{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and Imputation using Auto-Encoder\n",
    "\n",
    "The idea is to train a dense neural network as an auto-encoder to fill in missing values.\n",
    "\n",
    "\n",
    "## Outputs\n",
    "Creates output files in the \"predictions\" directory.\n",
    "Imputes as much as possible all NaNs in both train and test files and adds predictions.\n",
    "\n",
    "**IMPORTANT**: Preidictions in the train set were created by the Auto-Encoder!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('data/trainSet.txt')\n",
    "test = pd.read_csv('data/testSet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definde columns of interest\n",
    "cols_out = ['PatientID', 'ImageFile', 'Hospital', 'Prognosis']\n",
    "binary_vars = ['RespiratoryFailure', 'Sex', 'Cough', 'DifficultyInBreathing', 'CardiovascularDisease']\n",
    "impute_cols = [i for i in train.columns if i not in cols_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder should work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    regularizer = keras.regularizers.l1_l2(l1=0, l2=0.005)\n",
    "    \n",
    "    inputs = keras.Input(shape=(16,))\n",
    "    x = keras.layers.Dense(16, activation='selu')(inputs)\n",
    "    # build a little auto-encoder\n",
    "    x = keras.layers.Dense(80, activation='selu', kernel_regularizer=regularizer)(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    # bottleneck\n",
    "    x = keras.layers.Dense(4, activation='selu', kernel_regularizer=regularizer)(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    x = keras.layers.Dense(80, activation='selu', kernel_regularizer=regularizer)(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "    out1 = keras.layers.Dense(16, activation='sigmoid', name='imputing')(x)\n",
    "    out2 = keras.layers.Dense(1, activation='sigmoid', name='classifying')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, {'impute': out1, 'classify':out2})\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/keras-team/keras/issues/7065\n",
    "# Calculate MSE only on known values\n",
    "def masked_mse(mask_value=-1):\n",
    "    def f(y_true, y_pred):\n",
    "        mask_true = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "        masked_squared_error = K.square(mask_true * (y_true - y_pred))\n",
    "        masked_mse = K.sum(masked_squared_error, axis=-1) / K.sum(mask_true, axis=-1)\n",
    "        return masked_mse * 100\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "# Validate imputation by removing one nan extra per column\n",
    "def imputer_validation(valid_set):\n",
    "    \"\"\"\n",
    "    Function to remove extra fields from data for validation.\n",
    "    \"\"\"\n",
    "    fields_removed = valid_set.copy()\n",
    "    imputer_mask = np.zeros(valid_set.shape)\n",
    "    for n, row in enumerate(fields_removed):\n",
    "        non_nan = np.where(row != -1)[0]\n",
    "        set_nan = np.random.choice(non_nan)\n",
    "        fields_removed[n, set_nan] = -1\n",
    "        imputer_mask[n, set_nan] = True\n",
    "    \n",
    "    return fields_removed, imputer_mask\n",
    "\n",
    "\n",
    "# helper to calculate scores\n",
    "def calculate_score(x_true, x_pred, errorfun='mse', scaler=None):\n",
    "    if scaler:\n",
    "        x_true = scaler.inverse_transform(x_true.copy())\n",
    "        x_pred = scaler.inverse_transform(x_pred.copy())\n",
    "        x_true = np.clip(x_true, a_min=-1, a_max=None)\n",
    "        x_pred = np.clip(x_pred, a_min=-1, a_max=None)\n",
    "    if errorfun == 'mse':\n",
    "        score = mean_squared_error(x_true, x_pred)\n",
    "    elif errorfun == 'acc':\n",
    "        score = accuracy_score(x_true, x_pred > 0.5)\n",
    "    elif errorfun == \"masked_mse\":\n",
    "        score = masked_mse(-1)(x_true, x_pred)\n",
    "        score = np.mean(score)\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def post_processing(original_df, predicted_values, classify, scaler=None):\n",
    "    # Post processing\n",
    "    nan_mask = np.isnan(original_df)\n",
    "    previous_values = original_df.copy().values\n",
    "    imputed_thing = np.zeros(previous_values.shape)\n",
    "\n",
    "    # Rescale values and add to empty matrix\n",
    "    if scaler is not None:\n",
    "        predicted_values = MM.inverse_transform(predicted_values)\n",
    "    \n",
    "    imputed_thing[nan_mask] = predicted_values[nan_mask]\n",
    "    # Clip negatives\n",
    "    imputed_thing = np.clip(imputed_thing, a_min=0, a_max=None) \n",
    "    # Add known values\n",
    "    imputed_thing[nan_mask==False] = previous_values[nan_mask==False]\n",
    "    \n",
    "    # Add classification and column names, binarize binary values\n",
    "    df_out = pd.DataFrame(imputed_thing, columns=original_df.columns)\n",
    "    df_out[binary_vars] = (df_out[binary_vars] > 0.5) * 1.0\n",
    "    df_out['Prognosis'] = classify > 0.5\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global vars\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "OPTIMIZER = keras.optimizers.Adam(lr=0.0005)\n",
    "CALLBACKS = [early_stopping]\n",
    "LOSS = {'impute': masked_mse(), 'classify': 'binary_crossentropy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprare data for training\n",
    "train_clean = train[impute_cols]\n",
    "train_y = train['Prognosis'] == 'MILD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs, mses0, mses1, imps0, imps1, trues, preds, indices, hosp_val = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "train_mask = np.isnan(train_clean).values\n",
    "\n",
    "for hosp in np.unique(train.Hospital):\n",
    "    model = create_model()\n",
    "    model.compile(optimizer=OPTIMIZER, \n",
    "                  loss=LOSS,\n",
    "                  metrics={'impute': 'mse', 'classify': 'accuracy'})\n",
    "    MM = MinMaxScaler(clip=True)\n",
    "    \n",
    "    tr = np.where(train.Hospital != hosp)[0]\n",
    "    vl = np.where(train.Hospital == hosp)[0]\n",
    "\n",
    "    # Remove Nans\n",
    "    x_train = train_clean.iloc[tr].copy().fillna(0)\n",
    "    x_valid = train_clean.iloc[vl].copy().fillna(0)\n",
    "    # Define y-values\n",
    "    y_train = train_y.iloc[tr]\n",
    "    y_valid = train_y.iloc[vl]\n",
    "    # Scale data from 0 to 1\n",
    "    x_train = MM.fit_transform(x_train)\n",
    "    x_valid = MM.transform(x_valid)\n",
    "    \n",
    "    # Set former nan values to -1\n",
    "    x_train[train_mask[tr]] = -1\n",
    "    x_valid[train_mask[vl]] = -1\n",
    "    \n",
    "    # Fit Model\n",
    "    model.fit(x_train, {'impute':x_train, 'classify': y_train}, verbose=0, \n",
    "              callbacks=CALLBACKS, validation_split=0.15,\n",
    "             epochs=250)\n",
    "    \n",
    "    # Predict the things\n",
    "    prediction = model.predict(x_valid)\n",
    "    preds.append(MM.inverse_transform(prediction['impute']))\n",
    "\n",
    "    pred_val, pred_y = prediction['impute'], prediction['classify']\n",
    "    \n",
    "    \n",
    "    # Returns metrics, weirdly\n",
    "    _, _, _, train_acc, train_mse = model.evaluate(x_train, \n",
    "                                                   {'impute':x_train, \n",
    "                                                    'classify': y_train}, \n",
    "                                                   verbose=0)\n",
    "    \n",
    "    # Set previous NAN to -1\n",
    "    pred_val[train_mask[vl]] = -1\n",
    "    x_valid[train_mask[vl]] = -1\n",
    "    \n",
    "    # imputer validation:\n",
    "    x_impute, impute_mask = imputer_validation(x_valid)\n",
    "    \n",
    "    imputer_predict = model.predict(x_impute)['impute']\n",
    "    imputer_predict[impute_mask==False] = -1\n",
    "    \n",
    "    validation_mask = x_valid.copy()\n",
    "    validation_mask[impute_mask==False] = -1\n",
    "    \n",
    "    # imputer error\n",
    "    imp0 = calculate_score(validation_mask, \n",
    "                            imputer_predict, errorfun='masked_mse')\n",
    "    imp1 = calculate_score(validation_mask, \n",
    "                            imputer_predict, errorfun='masked_mse', scaler=MM)\n",
    "    \n",
    "    # Keepingt track\n",
    "    imps0.append(imp0)\n",
    "    imps1.append(imp1)\n",
    "    mses0.append(calculate_score(x_valid, pred_val, scaler=MM, errorfun='masked_mse'))\n",
    "    mses1.append(calculate_score(x_valid, pred_val, errorfun='masked_mse'))\n",
    "    accs.append(calculate_score(y_valid, pred_y, errorfun='acc'))\n",
    "    trues.append(MM.inverse_transform(x_valid))\n",
    "    preds.append(MM.inverse_transform(prediction['impute']))\n",
    "    print(f\"Split {hosp}, with validation n = {x_valid.shape[0]}: \\nRescaled MSE - {mses0[-1]:4.2f} \" +\n",
    "          f\"MSE - {mses1[-1]:4.2f} \" +\n",
    "          f\"Acc - {accs[-1]:4.2f}\\n\" +\n",
    "          f\"Impute MSE - {imps0[-1]:4.2f} \" +\n",
    "          f\"Impute MSE scaled - {imps1[-1]:4.2f}\")\n",
    "          \n",
    "    print(f\"Train - MSE {train_mse:4.3f}, ACC {train_acc:4.3f}\")\n",
    "    \n",
    "    indices.append(vl)\n",
    "    hosp_val.append([hosp] * len(vl))\n",
    "    print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Training and Creating Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer=OPTIMIZER, \n",
    "                  loss=LOSS,\n",
    "                  metrics={'impute': 'mae', 'classify': 'accuracy'})\n",
    "\n",
    "MM = MinMaxScaler(clip=True)\n",
    "\n",
    "# Transform Data:\n",
    "x_train = train_clean.copy().fillna(0)\n",
    "# Define y-values\n",
    "y_train = train_y\n",
    "# Scale data from 0 to 1\n",
    "x_train = MM.fit_transform(x_train)\n",
    "# Set former nan values to -1\n",
    "x_train[train_mask] = -1\n",
    "\n",
    "\n",
    "model.fit(x_train, {'impute':x_train, 'classify': y_train}, verbose=1, callbacks=CALLBACKS, \n",
    "          validation_split=0.15, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(x_train)\n",
    "train_imputations = train_predictions['impute']\n",
    "train_classify = train_predictions['classify']\n",
    "\n",
    "train_out = post_processing(train_clean, train_imputations, train_classify, MM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing columns\n",
    "train_out[['PatientID', 'ImageFile', 'Hospital']] = train[['PatientID', 'ImageFile', 'Hospital']]\n",
    "# Change order to original\n",
    "train_out = train_out[train.columns]\n",
    "\n",
    "train_out.to_csv('predictions/simon_TRAIN_impute_classify.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean = test[impute_cols] \n",
    "x_test = test_clean.copy().fillna(0)\n",
    "x_test = MM.transform(x_test)\n",
    "x_test[np.isnan(test_clean)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predidctions\n",
    "imputations = predictions['impute']\n",
    "classify = predictions['classify']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = post_processing(test_clean, imputations, classify, MM)\n",
    "\n",
    "test_out[test_out.Prognosis==True] = \"MILD\"\n",
    "test_out[test_out.Prognosis==False] = \"SEVERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing columns\n",
    "test_out[['PatientID', 'ImageFile', 'Hospital']] = test[['PatientID', 'ImageFile', 'Hospital']]\n",
    "# Change order to original\n",
    "test_out = test_out[test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "test_out.to_csv('predictions/simon_TEST_impute_classify.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Handson",
   "language": "python",
   "name": "handson_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
